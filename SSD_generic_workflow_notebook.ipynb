{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objet Detection using Single Shot Multibox Detetor (SSD)\n",
    "---\n",
    "\n",
    "This is a Keras port of the SSD model architecture introduced by Wei Liu et al. in the paper [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325)\n",
    "and originally implemented by Pierluigi Ferrari & can be found [here](https://github.com/pierluigiferrari/ssd_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from executor import executor\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Inference\n",
    "---\n",
    "Give all Hyperparameters here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-Configration for Training/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting GPU utilization\n",
    "limit_gpu = True # True: Enable TF's limit memory graph; False: Not enable\n",
    "mode = 'training' # either 'training' or 'inference'\n",
    "# Image property\n",
    "img_height = 300 # Height of image\n",
    "img_width = 300 # Width of image\n",
    "img_channels = 3 # Color channel, 3 for RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2(A): Data Loading for Training\n",
    "Provide here image directories, annotations, imagesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Optional: If you have enough memory, consider loading the images into memory as it is much faster\n",
    "annotation_type = 'csv'\n",
    "train_load_images_into_memory = True # True: Will load all images into memory; False: Keeeps on disk, but much slower\n",
    "validation_load_images_into_memory = True #same as above\n",
    "\n",
    "# Dataset location\n",
    "train_img_dir = './udacity_driving_datasets/'\n",
    "train_annotation_dir = './udacity_driving_datasets/labels_train.csv'\n",
    "#train_image_set_filename = './dataset/training/ImageSets/Main/trainval.txt'\n",
    "\n",
    "val_img_dir = './udacity_driving_datasets/'\n",
    "val_annotation_dir = './udacity_driving_datasets/labels_val.csv'\n",
    "#val_image_set_filename = './dataset/test/ImageSets/Main/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2(B): Video or Data loading for Inference\n",
    "Give either video or set of images as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_path = 'funny_dog.mp4'\n",
    "video_to_frames_export_path = './assets/frames_data'\n",
    "# TODO: Create Inference logic for image dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Common Hyperparameter\n",
    "This will remain common for both service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['background', 'car', 'truck', 'pedestrian', 'bicyclist', 'light']\n",
    "n_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4(A): Training Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "l2_regularization = 0.0005\n",
    "pos_iou_threshold = 0.5\n",
    "learning_rate = 0.001\n",
    "steps_per_epoch = 1000\n",
    "batch_size = 16\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step  4(B): Inference Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path= './weights/VGG_VOC0712_SSD_300x300_iter_120000.h5' # Load weights\n",
    "confidence_threshold= 0.6 # Threshold to select prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5(A): Saving produced Training assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Weights\n",
    "weight_save_path = './assets/weights/traffic'\n",
    "\n",
    "# Log csv\n",
    "csv_log_save_path = './assets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step  5(B): Saving Inference assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_frames_export_path= './assets/results' # Here frames with predicted bounding box will be saved\n",
    "video_output_path = \"./assets\" # Here video with predicted bounding box will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Invoking Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[INFO]... You have chosen to load data into memory\n",
      "Loading images into memory: 100%|██████████| 18000/18000 [01:22<00:00, 218.75it/s]\n",
      "Loading images into memory: 100%|██████████| 4241/4241 [00:18<00:00, 231.30it/s]\n",
      "[INFO]...Time taken by Data loading/transformation Job is 1.70 min(s)\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "tracking <tf.Variable 'conv4_3_norm/conv4_3_norm_gamma:0' shape=(512,) dtype=float32> gamma\n",
      "WARNING:tensorflow:From /home/akash/project/Object-Detection-using-SSD/keras_loss_function/keras_ssd_loss.py:95: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/akash/project/Object-Detection-using-SSD/keras_loss_function/keras_ssd_loss.py:133: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/akash/project/Object-Detection-using-SSD/keras_loss_function/keras_ssd_loss.py:74: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/akash/project/Object-Detection-using-SSD/keras_loss_function/keras_ssd_loss.py:166: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "[INFO]...Number of images in the training dataset: 18000\n",
      "[INFO]...Number of images in the validation dataset: 4241\n",
      "[INFO]...Weights will be saved at ./assets/weights/traffic\n",
      "WARNING:tensorflow:From /home/akash/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 672s 672ms/step - loss: 7.7239 - val_loss: 4.9466\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.94664, saving model to ./assets/weights/traffic/ssd_epoch-01_loss-7.7239.hfd5\n",
      "At end of Epoch 0 loss is 7.7239 and val_loss is 4.9466\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 5.2955 - val_loss: 3.8851\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.94664 to 3.88510, saving model to ./assets/weights/traffic/ssd_epoch-02_loss-5.2955.hfd5\n",
      "At end of Epoch 1 loss is 5.2955 and val_loss is 3.8851\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 653s 653ms/step - loss: 4.8577 - val_loss: 3.9834\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.88510\n",
      "At end of Epoch 2 loss is 4.8577 and val_loss is 3.9834\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 656s 656ms/step - loss: 4.6402 - val_loss: 3.4571\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.88510 to 3.45711, saving model to ./assets/weights/traffic/ssd_epoch-04_loss-4.6402.hfd5\n",
      "At end of Epoch 3 loss is 4.6402 and val_loss is 3.4571\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 646s 646ms/step - loss: 4.5264 - val_loss: 3.4975\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.45711\n",
      "At end of Epoch 4 loss is 4.5264 and val_loss is 3.4975\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 644s 644ms/step - loss: 4.4771 - val_loss: 3.4231\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.45711 to 3.42307, saving model to ./assets/weights/traffic/ssd_epoch-06_loss-4.4771.hfd5\n",
      "At end of Epoch 5 loss is 4.4771 and val_loss is 3.4231\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 656s 656ms/step - loss: 4.4359 - val_loss: 3.3329\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.42307 to 3.33295, saving model to ./assets/weights/traffic/ssd_epoch-07_loss-4.4359.hfd5\n",
      "At end of Epoch 6 loss is 4.4359 and val_loss is 3.3329\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 643s 643ms/step - loss: 4.3809 - val_loss: 3.3800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.33295\n",
      "At end of Epoch 7 loss is 4.3809 and val_loss is 3.3800\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 643s 643ms/step - loss: 4.3639 - val_loss: 3.8657\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.33295\n",
      "At end of Epoch 8 loss is 4.3639 and val_loss is 3.8657\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 642s 642ms/step - loss: 4.3141 - val_loss: 3.1411\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.33295 to 3.14113, saving model to ./assets/weights/traffic/ssd_epoch-10_loss-4.3141.hfd5\n",
      "At end of Epoch 9 loss is 4.3141 and val_loss is 3.1411\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 641s 641ms/step - loss: 4.2999 - val_loss: 3.0318\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.14113 to 3.03177, saving model to ./assets/weights/traffic/ssd_epoch-11_loss-4.2999.hfd5\n",
      "At end of Epoch 10 loss is 4.2999 and val_loss is 3.0318\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 644s 644ms/step - loss: 4.2741 - val_loss: 3.0032\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.03177 to 3.00325, saving model to ./assets/weights/traffic/ssd_epoch-12_loss-4.2741.hfd5\n",
      "At end of Epoch 11 loss is 4.2741 and val_loss is 3.0032\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 656s 656ms/step - loss: 4.2515 - val_loss: 2.8965\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.00325 to 2.89648, saving model to ./assets/weights/traffic/ssd_epoch-13_loss-4.2515.hfd5\n",
      "At end of Epoch 12 loss is 4.2515 and val_loss is 2.8965\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 640s 640ms/step - loss: 4.2642 - val_loss: 2.9664\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.89648\n",
      "At end of Epoch 13 loss is 4.2642 and val_loss is 2.9664\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 644s 644ms/step - loss: 4.2550 - val_loss: 3.5611\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.89648\n",
      "At end of Epoch 14 loss is 4.2550 and val_loss is 3.5611\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.2113 - val_loss: 3.2098\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.89648\n",
      "At end of Epoch 15 loss is 4.2113 and val_loss is 3.2098\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 646s 646ms/step - loss: 4.2025 - val_loss: 3.3097\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.89648\n",
      "At end of Epoch 16 loss is 4.2025 and val_loss is 3.3097\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.2270 - val_loss: 3.2665\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.89648\n",
      "At end of Epoch 17 loss is 4.2270 and val_loss is 3.2665\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.1757 - val_loss: 3.1021\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.89648\n",
      "At end of Epoch 18 loss is 4.1757 and val_loss is 3.1021\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.1896 - val_loss: 3.2041\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.89648\n",
      "At end of Epoch 19 loss is 4.1896 and val_loss is 3.2041\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 646s 646ms/step - loss: 4.1700 - val_loss: 3.1529\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.89648\n",
      "At end of Epoch 20 loss is 4.1700 and val_loss is 3.1529\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.2074 - val_loss: 3.2813\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.89648\n",
      "At end of Epoch 21 loss is 4.2074 and val_loss is 3.2813\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.1532 - val_loss: 2.9646\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.89648\n",
      "At end of Epoch 22 loss is 4.1532 and val_loss is 2.9646\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.1385 - val_loss: 3.4121\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.89648\n",
      "At end of Epoch 23 loss is 4.1385 and val_loss is 3.4121\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.1546 - val_loss: 3.2166\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.89648\n",
      "At end of Epoch 24 loss is 4.1546 and val_loss is 3.2166\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.1195 - val_loss: 3.1596\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.89648\n",
      "At end of Epoch 25 loss is 4.1195 and val_loss is 3.1596\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.1113 - val_loss: 3.1606\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.89648\n",
      "At end of Epoch 26 loss is 4.1113 and val_loss is 3.1606\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1149 - val_loss: 2.9947\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.89648\n",
      "At end of Epoch 27 loss is 4.1149 and val_loss is 2.9947\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1350 - val_loss: 3.2437\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.89648\n",
      "At end of Epoch 28 loss is 4.1350 and val_loss is 3.2437\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1357 - val_loss: 3.2178\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.89648\n",
      "At end of Epoch 29 loss is 4.1357 and val_loss is 3.2178\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1069 - val_loss: 3.2588\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.89648\n",
      "At end of Epoch 30 loss is 4.1069 and val_loss is 3.2588\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1196 - val_loss: 2.9591\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.89648\n",
      "At end of Epoch 31 loss is 4.1196 and val_loss is 2.9591\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 647s 647ms/step - loss: 4.1001 - val_loss: 3.3051\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.89648\n",
      "At end of Epoch 32 loss is 4.1001 and val_loss is 3.3051\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.1183 - val_loss: 3.1472\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.89648\n",
      "At end of Epoch 33 loss is 4.1183 and val_loss is 3.1472\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.1122 - val_loss: 3.0862\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.89648\n",
      "At end of Epoch 34 loss is 4.1122 and val_loss is 3.0862\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0856 - val_loss: 2.7370\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.89648 to 2.73697, saving model to ./assets/weights/traffic/ssd_epoch-36_loss-4.0856.hfd5\n",
      "At end of Epoch 35 loss is 4.0856 and val_loss is 2.7370\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0753 - val_loss: 2.7528\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.73697\n",
      "At end of Epoch 36 loss is 4.0753 and val_loss is 2.7528\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.0853 - val_loss: 2.9708\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.73697\n",
      "At end of Epoch 37 loss is 4.0853 and val_loss is 2.9708\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0633 - val_loss: 3.2925\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.73697\n",
      "At end of Epoch 38 loss is 4.0633 and val_loss is 3.2925\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0663 - val_loss: 3.1249\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.73697\n",
      "At end of Epoch 39 loss is 4.0663 and val_loss is 3.1249\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.0949 - val_loss: 2.9999\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.73697\n",
      "At end of Epoch 40 loss is 4.0949 and val_loss is 2.9999\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0700 - val_loss: 3.2294\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.73697\n",
      "At end of Epoch 41 loss is 4.0700 and val_loss is 3.2294\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.0370 - val_loss: 3.1335\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.73697\n",
      "At end of Epoch 42 loss is 4.0370 and val_loss is 3.1335\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 648s 648ms/step - loss: 4.0584 - val_loss: 3.1584\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.73697\n",
      "At end of Epoch 43 loss is 4.0584 and val_loss is 3.1584\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 649s 649ms/step - loss: 4.0605 - val_loss: 3.1201\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.73697\n",
      "At end of Epoch 44 loss is 4.0605 and val_loss is 3.1201\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 4.0611"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "with mlflow.start_run(experiment_id=1, run_name='ssd_traffic'):\n",
    "    mlflow.set_tags({'dataset': 'udacity traffic', 'ssd':'ssd300'})\n",
    "    executor(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondad442884048ed43e0a1ceca58168dba20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
